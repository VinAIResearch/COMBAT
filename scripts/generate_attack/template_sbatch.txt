#!/bin/bash
#SBATCH --partition={partition}
#SBATCH --output={slurm_log}/%x-%j.out
#SBATCH --error={slurm_log}/%x-%j.out
#SBATCH --job-name={job_name}
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gpus-per-node=1
#SBATCH --cpus-per-task={cpu_per_task}
#SBATCH --mem={mem}G
#SBATCH --mail-user=v.dangnm12@vinai.io
#SBATCH --mail-type=END
#SBATCH --mail-type=FAIL
{slurm_config}


srun --container-image=/lustre/scratch/client/vinai/users/dangnm12/setup/docker_images/dc-miniconda3-py:38-4.10.3-cuda11.4.2-cudnn8-ubuntu20.04.sqsh \
     --container-mounts=/lustre/scratch/client/vinai/users/dangnm12/:/root/ \
     --container-workdir=/root/ \
     /bin/bash -c \
     "
     export HTTP_PROXY=http://proxytc.vingroup.net:9090/
     export HTTPS_PROXY=http://proxytc.vingroup.net:9090/
     export http_proxy=http://proxytc.vingroup.net:9090/
     export https_proxy=http://proxytc.vingroup.net:9090/

     export HF_DATASETS_CACHE=/root/cache/huggingface/datasets
     export TRANSFORMERS_CACHE=/root/cache/huggingface/transformers
     export TFHUB_CACHE_DIR=/root/cache/tfhub_modules

     export TF_FORCE_GPU_ALLOW_GROWTH=true
     export TRANSFORMERS_OFFLINE=1
     export HF_DATASETS_OFFLINE=1
     export TOKENIZERS_PARALLELISM=false

     source /opt/conda/bin/activate

     cd /root
     conda activate /root/miniconda3/envs/{env}

     cd {workspace}
     wandb offline
     {cmd}
     "
